     1→---
     2→name: research
     3→description: Comprehensive research, analysis, and content extraction system. Multi-source parallel research using available researcher agents. Deep content analysis with extended thinking. Intelligent retrieval for difficult sites. Fabric pattern selection for 242+ specialized prompts. USE WHEN user says 'do research', 'extract wisdom', 'analyze content', 'find information about', or requests web/content research.
     4→---
     5→
     6→# Research Skill
     7→
     8→## API Keys Required
     9→
    10→**This skill works best with these optional API keys configured in `~/.env`:**
    11→
    12→| Feature | API Key | Get It From |
    13→|---------|---------|-------------|
    14→| Perplexity Research | `PERPLEXITY_API_KEY` | https://perplexity.ai/settings/api |
    15→| Gemini Research | `GOOGLE_API_KEY` | https://aistudio.google.com/app/apikey |
    16→| BrightData Scraping | `BRIGHTDATA_API_KEY` | https://brightdata.com |
    17→
    18→**Works without API keys:**
    19→- Claude-based research (uses built-in WebSearch)
    20→- Basic web fetching (uses built-in WebFetch)
    21→- Fabric patterns (if Fabric CLI installed)
    22→
    23→---
    24→
    25→## Workflow Routing
    26→
    27→### Multi-Source Research Workflows
    28→
    29→**When user requests comprehensive parallel research:**
    30→Examples: "do research on X", "research this topic", "find information about Y", "investigate this subject"
    31→→ **READ:** `${PAI_DIR}/Skills/research/workflows/conduct.md`
    32→→ **EXECUTE:** Parallel multi-agent research using available researcher agents
    33→
    34→**When user requests Claude-based research (FREE - no API keys):**
    35→Examples: "use claude for research", "claude research on X", "use websearch to research Y"
    36→→ **READ:** `${PAI_DIR}/Skills/research/workflows/claude-research.md`
    37→→ **EXECUTE:** Intelligent query decomposition with Claude's WebSearch
    38→
    39→**When user requests Perplexity research (requires PERPLEXITY_API_KEY):**
    40→Examples: "use perplexity to research X", "perplexity research on Y"
    41→→ **READ:** `${PAI_DIR}/Skills/research/workflows/perplexity-research.md`
    42→→ **EXECUTE:** Fast web search with query decomposition via Perplexity API
    43→
    44→**When user requests interview preparation:**
    45→Examples: "prepare interview questions for X", "interview research on Y"
    46→→ **READ:** `${PAI_DIR}/Skills/research/workflows/interview-research.md`
    47→→ **EXECUTE:** Interview prep with diverse question generation
    48→
    49→### Content Retrieval Workflows
    50→
    51→**When user indicates difficulty accessing content:**
    52→Examples: "can't get this content", "site is blocking me", "CAPTCHA blocking"
    53→→ **READ:** `${PAI_DIR}/Skills/research/workflows/retrieve.md`
    54→→ **EXECUTE:** Escalation through layers (WebFetch → BrightData → Apify)
    55→
    56→**When user provides YouTube URL:**
    57→Examples: "get this youtube video", "extract from youtube URL"
    58→→ **READ:** `${PAI_DIR}/Skills/research/workflows/youtube-extraction.md`
    59→→ **EXECUTE:** YouTube content extraction using fabric -y
    60→
    61→**When user requests web scraping:**
    62→Examples: "scrape this site", "extract data from this website"
    63→→ **READ:** `${PAI_DIR}/Skills/research/workflows/web-scraping.md`
    64→→ **EXECUTE:** Web scraping techniques and tools
    65→
    66→### Fabric Pattern Processing
    67→
    68→**When user requests Fabric pattern usage:**
    69→Examples: "use fabric to X", "create threat model", "summarize with fabric"
    70→→ **READ:** `${PAI_DIR}/Skills/research/workflows/fabric.md`
    71→→ **EXECUTE:** Auto-select best pattern from 242+ Fabric patterns
    72→
    73→### Content Enhancement Workflows
    74→
    75→**When user requests content enhancement:**
    76→Examples: "enhance this content", "improve this draft"
    77→→ **READ:** `${PAI_DIR}/Skills/research/workflows/enhance.md`
    78→→ **EXECUTE:** Content improvement and refinement
    79→
    80→**When user requests knowledge extraction:**
    81→Examples: "extract knowledge from X", "get insights from this"
    82→→ **READ:** `${PAI_DIR}/Skills/research/workflows/extract-knowledge.md`
    83→→ **EXECUTE:** Knowledge extraction and synthesis
    84→
    85→---
    86→
    87→## Multi-Source Research
    88→
    89→### Three Research Modes
    90→
    91→**QUICK RESEARCH MODE:**
    92→- User says "quick research" → Launch 1 agent per researcher type
    93→- **Timeout: 2 minutes**
    94→- Best for: Simple queries, straightforward questions
    95→
    96→**STANDARD RESEARCH MODE (Default):**
    97→- Default for most research requests → Launch 3 agents per researcher type
    98→- **Timeout: 3 minutes**
    99→- Best for: Most research needs, comprehensive coverage
   100→
   101→**EXTENSIVE RESEARCH MODE:**
   102→- User says "extensive research" → Launch 8 agents per researcher type
   103→- **Timeout: 10 minutes**
   104→- Best for: Deep-dive research, comprehensive reports
   105→
   106→### Available Research Agents
   107→
   108→Check `${PAI_DIR}/Agents/` for agents with "researcher" in their name:
   109→- `claude-researcher` - Uses Claude's WebSearch (FREE, no API key needed)
   110→- `perplexity-researcher` - Uses Perplexity API (requires PERPLEXITY_API_KEY)
   111→- `gemini-researcher` - Uses Gemini API (requires GOOGLE_API_KEY)
   112→
   113→### Speed Benefits
   114→
   115→- ❌ **Old approach**: Sequential searches → 5-10 minutes
   116→- ✅ **Quick mode**: 1 agent per type → **2 minute timeout**
   117→- ✅ **Standard mode**: 3 agents per type → **3 minute timeout**
   118→- ✅ **Extensive mode**: 8 agents per type → **10 minute timeout**
   119→
   120→---
   121→
   122→## Intelligent Content Retrieval
   123→
   124→### Three-Layer Escalation System
   125→
   126→**Layer 1: Built-in Tools (Try First - FREE)**
   127→- WebFetch - Standard web content fetching
   128→- WebSearch - Search engine queries
   129→- When to use: Default for all content retrieval
   130→
   131→**Layer 2: BrightData MCP (requires BRIGHTDATA_API_KEY)**
   132→- CAPTCHA solving via Scraping Browser
   133→- Advanced JavaScript rendering
   134→- When to use: Bot detection blocking, CAPTCHA protection
   135→
   136→**Layer 3: Apify MCP (requires Apify account)**
   137→- Specialized site scrapers (Instagram, LinkedIn, etc.)
   138→- Complex extraction logic
   139→- When to use: Layers 1 and 2 both failed
   140→
   141→**Critical Rules:**
   142→- Always try simplest approach first (Layer 1)
   143→- Escalate only when previous layer fails
   144→- Document which layers were used and why
   145→
   146→---
   147→
   148→## Fabric Pattern Selection
   149→
   150→### Categories (242+ Patterns)
   151→
   152→**Threat Modeling & Security:**
   153→- `create_threat_model`, `create_stride_threat_model`
   154→- `analyze_threat_report`, `analyze_incident`
   155→
   156→**Summarization:**
   157→- `summarize`, `create_5_sentence_summary`
   158→- `summarize_meeting`, `summarize_paper`, `youtube_summary`
   159→
   160→**Wisdom Extraction:**
   161→- `extract_wisdom`, `extract_article_wisdom`
   162→- `extract_insights`, `extract_main_idea`
   163→
   164→**Analysis:**
   165→- `analyze_claims`, `analyze_code`, `analyze_debate`
   166→- `analyze_logs`, `analyze_paper`
   167→
   168→**Content Creation:**
   169→- `create_prd`, `create_design_document`
   170→- `create_mermaid_visualization`, `create_user_story`
   171→
   172→**Improvement:**
   173→- `improve_writing`, `improve_prompt`, `review_code`
   174→
   175→### Usage
   176→
   177→```bash
   178→# Auto-select pattern based on intent
   179→fabric [input] -p [selected_pattern]
   180→
   181→# From URL
   182→fabric -u "URL" -p [pattern]
   183→
   184→# From YouTube
   185→fabric -y "YOUTUBE_URL" -p [pattern]
   186→```
   187→
   188→---
   189→
   190→## File Organization
   191→
   192→### Working Directory (Scratchpad)
   193→```
   194→${PAI_DIR}/scratchpad/YYYY-MM-DD-HHMMSS_research-[topic]/
   195→├── raw-outputs/
   196→├── synthesis-notes.md
   197→└── draft-report.md
   198→```
   199→
   200→### Permanent Storage (History)
   201→```
   202→${PAI_DIR}/History/research/YYYY-MM/YYYY-MM-DD_[topic]/
   203→├── README.md
   204→├── research-report.md
   205→└── metadata.json
   206→```
   207→
   208→---
   209→
   210→## Key Principles
   211→
   212→1. **Parallel execution** - Launch multiple agents simultaneously
   213→2. **Hard timeouts** - Don't wait indefinitely, proceed with partial results
   214→3. **Simplest first** - Always try free tools before paid services
   215→4. **Auto-routing** - Skill analyzes intent and activates appropriate workflow
   216→
   217→---
   218→
   219→## Workflow Files
   220→
   221→| Workflow | File | API Keys Needed |
   222→|----------|------|-----------------|
   223→| Multi-Source Research | `workflows/conduct.md` | Varies by agent |
   224→| Claude Research | `workflows/claude-research.md` | None (FREE) |
   225→| Perplexity Research | `workflows/perplexity-research.md` | PERPLEXITY_API_KEY |
   226→| Interview Prep | `workflows/interview-research.md` | None |
   227→| Content Retrieval | `workflows/retrieve.md` | Optional: BRIGHTDATA_API_KEY |
   228→| YouTube Extraction | `workflows/youtube-extraction.md` | None (uses Fabric) |
   229→| Web Scraping | `workflows/web-scraping.md` | Optional: BRIGHTDATA_API_KEY |
   230→| Fabric Patterns | `workflows/fabric.md` | None |
   231→| Content Enhancement | `workflows/enhance.md` | None |
   232→| Knowledge Extraction | `workflows/extract-knowledge.md` | None |
   233→

<system-reminder>
Whenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.
</system-reminder>
