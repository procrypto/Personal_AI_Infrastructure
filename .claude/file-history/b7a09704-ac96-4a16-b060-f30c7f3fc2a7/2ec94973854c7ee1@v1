# nanochat - Synthesized Context

## Discovery Summary
- **First discovered**: 2026-01-10
- **Last updated**: 2026-01-10
- **Discovery depth**: Standard
- **Documentation quality**: Excellent (comprehensive README, inline docs)

---

## System Identity

**What it is**: Full-stack ChatGPT implementation by Andrej Karpathy.

**What it does**:
- Complete LLM training pipeline: tokenizer → pretraining → finetuning → inference
- Train 350M-2.2B parameter models for ~$100-1000
- Serve via FastAPI with ChatGPT-like UI
- Educational, hackable codebase (~8K lines)

**Key insight**: Fork of Karpathy's nanochat - likely used as internal team AI tool or reference implementation.

---

## Architecture Highlights

### Stack
- PyTorch 2.9+ with distributed training (DDP)
- BPE tokenization (HF tokenizers + tiktoken)
- FastAPI web server
- React-like embedded UI

### Training Pipeline
```
1. Tokenizer (BPE training, ~1 hour)
2. Base Pretraining (50-100B tokens, ~3 hours for d20)
3. Mid-training (conversation finetuning, ~30 min)
4. SFT (benchmark tasks, ~30 min)
5. RL (optional, GSM8K rewards)
6. Inference (FastAPI + ChatGPT UI)
```

### Model Scales
- d12 (125M): ~1 hour, $25
- d20 (350M): ~4 hours, $100 (GPT-1 level)
- d34 (2.2B): ~41 hours, $1000 (above GPT-2)

---

## Key Features

- **Special Tokens**: `<|user_start|>`, `<|assistant_start|>`, `<|python_start|>` for tool use
- **Sandboxed Execution**: Safe Python code execution with timeouts
- **KV Cache**: Efficient token-by-token inference
- **Multi-GPU**: Worker pool distribution

---

## Evaluation Tasks

- GSM8K (math), ARC (science), MMLU (knowledge)
- HumanEval (code), SmolTalk (conversation)
- Custom JSON task support

---

## Working Here

### Quick Start
```bash
uv sync --extra gpu
bash speedrun.sh  # Full $100 pipeline (~4 hours)
```

### Chat
```bash
python -m scripts.chat_web  # Web UI
python -m scripts.chat_cli -p "Your question"  # CLI
```

---

## Team Context

**Origin**: Forked from github.com/karpathy/nanochat
**Created**: January 2026 (208 commits imported)
**Purpose**: Internal AI tool / reference implementation
