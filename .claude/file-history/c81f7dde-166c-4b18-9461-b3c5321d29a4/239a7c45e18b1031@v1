# nanochat-deploy - Synthesized Context

## Discovery Summary
- **First discovered**: 2026-01-10
- **Last updated**: 2026-01-10
- **Discovery depth**: Standard
- **Documentation quality**: Good (comprehensive docs/)

---

## System Identity

**What it is**: GCP deployment infrastructure for NanoChat internal SQL assistant.

**What it does**:
- Deploys NanoChat model to GCE with GPU
- Provides chat interface for analysts
- Uses IAP for Google Workspace auth
- Manages model updates and versioning

**Key insight**: Makes the fine-tuned NanoChat model accessible to internal analysts via web chat.

---

## Architecture Highlights

### Stack
- Terraform for GCP provisioning
- GCE with T4/A100 GPU
- Identity-Aware Proxy (IAP)
- Python/FastAPI chat server

### Structure
```
terraform/gcp/    # Infrastructure code
api/              # Chat server
docker/           # Container configs
scripts/          # Deployment utilities
docs/             # User guides
```

---

## Cost Tiers

| Config | Monthly Cost |
|--------|-------------|
| T4 GPU (work hours) | ~$150/mo |
| T4 GPU (always on) | ~$350/mo |
| A100 GPU (always on) | ~$1,500/mo |

---

## Key Commands

```bash
# Deploy infrastructure
cd terraform/gcp
terraform init && terraform apply

# Update model
./scripts/update_model.sh <step_number>

# Monitor
gcloud compute ssh analyst-ai-server --command="sudo journalctl -u nanochat -f"
```

---

## Current Model

- **Version**: model_000171.pt (v3)
- **Training data**: 2,770 examples
- **Location**: Lambda Labs â†’ HuggingFace

---

## Team & Ownership

**Lead**: Victor (@vem)
**GCP Project**: bonkbotbeta
