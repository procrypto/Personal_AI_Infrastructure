# Roadmap

## Current Milestone: v1.1 Insight Pivot

### Phase 01: Turbo User Scan
**Goal:** Bring user-mode stage 1 to parity with group-mode scan speeds.
**Depends on:** —
**Research needed:** Medium (verify byte-level parser approach works for user aggregation).

Plans:
1. Profile current user scan to pinpoint bottlenecks (parser hooks, count aggregation).
2. Prototype byte-level metadata extractor for users (skip message bodies until filtering stage).
3. Port worker progress/events + whitelist application to the new fast path.
4. Regression test on 4.6 GB export, ensure status UX still accurate.

### Phase 02: Group-First UX
**Goal:** Make Group Mode the default experience without removing User Mode capabilities.
**Depends on:** Phase 01
**Research needed:** Low

Plans:
1. Update UI copy + radio defaults so Group Mode is pre-selected and highlighted.
2. Adjust onboarding flow/README to explain modes and when to switch.
3. Add persistence for last-used mode + warnings if user-mode scan may be slow.
4. Polish group selection UX (sorting, search, summary chips).

### Phase 03: Topic Mode Foundations
**Goal:** Introduce guided theme extraction over exported chat ZIPs with optional ad-hoc search.
**Depends on:** Phase 02
**Research needed:** High (local LLM feasibility, context windows, anonymization strategy).
**Status:** In progress (1/4 plans complete)

Plans:
1. ~~Create Topic Mode UX: upload ZIP of exported chats, choose theme(s) or enter ad-hoc search.~~ ✓
2. Build ZIP ingestion pipeline that indexes conversations (per chat, timestamp, participants, tokens).
3. Implement guided themes (features, bugs, frustrations, partnerships, content creation) with heuristics + local embedding/LLM passes.
4. Add optional ad-hoc keyword/LLM query field that reuses the same index.

### Phase 04: Local LLM & Anonymization Layer
**Goal:** Ensure topic analysis remains private-first, with anonymization if external calls are ever needed.
**Depends on:** Phase 03
**Research needed:** High (evaluate local models vs MCP connectors, anonymization techniques).

Plans:
1. Evaluate local LLM options (GGUF, llama.cpp, MCP connectors) for summarizing chat snippets.
2. Design anonymization pipeline (strip PII, map participants to pseudonyms, chunking rules) before any external call.
3. Implement configurable inference backends: local default, optional user-provided API keys, all behind a clear consent prompt.
4. Add diagnostics to show how many messages/topics were analyzed and whether anonymization was applied.

---
